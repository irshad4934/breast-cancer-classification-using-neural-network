# -*- coding: utf-8 -*-
"""Data Visualization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N_43DGZijEDnP9UyAoN6J4o0Nx3Vrw59

#Importing the Dependencies
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder

"""# Data Collection"""

# loading the breast cancer dataset from csv file to pandas data frame
breast_cancer_data = pd.read_csv('/content/data.csv')

"""# Exploratory Data Analysis"""

# printing the first five rows of the dataframe
breast_cancer_data.head()

# removing the unnmaed column
breast_cancer_data.drop(columns='Unnamed: 32', axis = 1, inplace=True)

breast_cancer_data.head()

breast_cancer_data.shape

# checking the data types
breast_cancer_data.info()

# removing the id column
breast_cancer_data.drop(columns='id', axis=1, inplace=True)

"""Diagnosis column is a CATEGORICAL columnm whereas remIning are continuous values"""

# checking for missing values
breast_cancer_data.isnull().sum()

"""As we can see, the dataset has no missing values

Statistical summary of the data - Descriptive Statistics
"""

breast_cancer_data.describe()

"""Check whether mean & median (50th Percentile) are close to each other

Checkin the distribution of target Variable
"""

breast_cancer_data['diagnosis'].value_counts()

# encoding the target column 
label_encode = LabelEncoder()

labels = label_encode.fit_transform(breast_cancer_data['diagnosis'])

breast_cancer_data['target'] = labels

breast_cancer_data.drop(columns='diagnosis', axis=1, inplace=True)

# diagnosis column removed
breast_cancer_data.head()

breast_cancer_data['target'].value_counts()

"""Benign --> 0

Malignant --> 1
"""

sns.countplot(x='target', data=breast_cancer_data)

"""There is a slight imbalance in the data. But it is fine in this case

Grouping the data based on the target
"""

breast_cancer_data.groupby('target').mean()

"""Inference: We can clearly see that for most of the features, the mean values are higher for Malignant(1) cases and lower for Benign(0) cases

# Data Visualization
"""

# countplot for the target column for checkin gthe distribution of target
sns.countplot(x='target', data=breast_cancer_data)

"""Distribution plot for all columns"""

# this is how we can get all the column names of the dataframe
for column in breast_cancer_data:
  print(column)

# creating a for loop to get the distribution plot for all columns
for column in breast_cancer_data:
  sns.displot(x=column, data=breast_cancer_data)

sns.distplot(x=breast_cancer_data.radius_mean)

"""Inference about distribution: Most of the features are right skewed

Pair plot

Pair plot takes a lot of time if the number of features is more. So we are going to take a random sample of the original dataset to make the pairplot
(Not plotting here)
"""

# pair plot
#sns.pairplot(df)
#plt.show()

"""Scatter plot of first 2 columns"""

# Select first column of the dataframe as a series
first_column = breast_cancer_data.iloc[:, 0]

# Select second column of the dataframe as a series
second_column = breast_cancer_data.iloc[:, 1]

print(first_column)
print('-----')
print(second_column)

# let's plot a scatter plot for 1st feature vs second feature
plt.scatter(x=first_column, y=second_column)

"""**Outliers Detection**

Box plot for visualizing the outliers in the dataset
"""

for column in breast_cancer_data:
    plt.figure()
    breast_cancer_data.boxplot([column])

"""As we can see here that most of the skewed features have Outliers

Correlation Matrix
"""

correlation_matrix = breast_cancer_data.corr()

# constructing a heat map to visualize the correlation matrix
plt.figure(figsize=(20,20))
sns.heatmap(correlation_matrix, cbar=True, fmt='.1f', annot=True, cmap='Blues')
plt.savefig('Correlation Heat map')

"""**Multicollinearity problem:**

Multicollinearity exists when an independent variable is highly correlated with one or more independent variables

We can remove the features if they have high +ve or -ve correlation between them

**Inference from EDA & Data Visualization:** 
1. No missing Values
2. All are continuous numerical values except for Target column
3. Mean is slightly more than the median for most of the features. So it is right skewed.
4. Slight imbalance in the dataset (Benign(0) cases are more than Malignant(1) cases
5. Mean of most features are clearly larger for Malignant cases compared to the benign cases (Groupby)
6. Most of the features have Outliers
7. Correlation Matrix reveal that most of the features are highly correlated. So we can remove certain features during Feature Selection
"""